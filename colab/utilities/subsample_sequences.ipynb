{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4161,
     "status": "ok",
     "timestamp": 1717112550538,
     "user": {
      "displayName": "Alexander Barnett",
      "userId": "00179978372066039901"
     },
     "user_tz": -600
    },
    "id": "0XyuLMSevda-",
    "outputId": "bed0174e-ab76-444b-e15a-8243434a9985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Change these file paths for each of the relevent autoregressive LLMs\n",
    "\n",
    "meta_data_filepath = \"/content/drive/MyDrive/Generative_Models/unconditional_generation/protgpt2_unconditional/generation_metadata_protgpt2.csv\"\n",
    "len_dist_filepath = \"/content/drive/MyDrive/Generative_Models/unconditional_generation/protgpt2_unconditional/uniref50_length_dist_protgpt2.json\"\n",
    "\n",
    "all_metadata_df = pd.read_csv(meta_data_filepath)\n",
    "with open(len_dist_filepath, \"r\") as f:\n",
    "  uniprot_length_dist =  json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1717112556950,
     "user": {
      "displayName": "Alexander Barnett",
      "userId": "00179978372066039901"
     },
     "user_tz": -600
    },
    "id": "WO6QP3vV2TZk",
    "outputId": "064f9987-a7a5-40aa-e280-49e115bda6a3"
   },
   "outputs": [],
   "source": [
    "#need to make sure we take the exact length 100 sequences the we selected previously\n",
    "fasta_filepath = \"/content/drive/MyDrive/Generative_Models/utilities/fold_inputs/all_len100.fa\"\n",
    "len100s = []\n",
    "\n",
    "with open(fasta_filepath, \"r\") as f:\n",
    "  fasta_sequences = f.read()\n",
    "\n",
    "for record in fasta_sequences.split('>')[1:]:\n",
    "  sequence_id = record.split('\\n')[0]\n",
    "  if meta_data_filepath.split(\"_\")[-1].split(\".\")[0] in sequence_id:\n",
    "    print(sequence_id)\n",
    "    len100s.append(sequence_id.split(\"_\")[-1])\n",
    "print(len100s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8267,
     "status": "ok",
     "timestamp": 1717112570441,
     "user": {
      "displayName": "Alexander Barnett",
      "userId": "00179978372066039901"
     },
     "user_tz": -600
    },
    "id": "2aYWz3K9yeJe",
    "outputId": "1cdfae70-fcc5-40e1-a3cb-18d8b287eeee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.83)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.25.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython\n",
    "#LLM outputs sometimes have artifacts. Correct these first.\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import re\n",
    "\n",
    "def is_valid_protein(sequence):\n",
    "  try:\n",
    "    Seq(str(sequence))\n",
    "    return True\n",
    "  except ValueError:\n",
    "    return False\n",
    "\n",
    "all_metadata_df.loc[:,'generated_sequence'] = all_metadata_df.loc[:,'generated_sequence'].apply(lambda x: re.sub(r'[\\s\\d]+', '', str(x)))\n",
    "all_metadata_df.loc[:,'generated_sequence'] = all_metadata_df.loc[all_metadata_df.loc[:,'generated_sequence'].apply(is_valid_protein),:]\n",
    "all_metadata_df.loc[:,'length'] = all_metadata_df.loc[:,'generated_sequence'].apply(lambda x: len(x))\n",
    "all_metadata_df.drop('conditions',inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 1409,
     "status": "ok",
     "timestamp": 1717112938225,
     "user": {
      "displayName": "Alexander Barnett",
      "userId": "00179978372066039901"
     },
     "user_tz": -600
    },
    "id": "xsAiV2gMwqpy"
   },
   "outputs": [],
   "source": [
    "subsampled_dfs = []\n",
    "for length, num_rows in uniprot_length_dist:\n",
    "  #need to make sure we take the exact length 100 sequences the we selected previously\n",
    "  if length == 100:\n",
    "    sampled_df = all_metadata_df.loc[all_metadata_df.entity_id.isin(len100s),:]\n",
    "  else:\n",
    "    sampled_df = all_metadata_df[all_metadata_df['length'] == length].sample(frac=1, random_state=42).reset_index(drop=True).head(num_rows)\n",
    "  if len(sampled_df) < num_rows:\n",
    "      print(f\"Warning: Only {len(filtered_df)} rows available for length {length}. Sampling all available rows.\")\n",
    "  subsampled_dfs.append(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 1042,
     "status": "ok",
     "timestamp": 1717112940804,
     "user": {
      "displayName": "Alexander Barnett",
      "userId": "00179978372066039901"
     },
     "user_tz": -600
    },
    "id": "vkYCbyu_yF0_"
   },
   "outputs": [],
   "source": [
    "clean_df = pd.concat(subsampled_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1717112956213,
     "user": {
      "displayName": "Alexander Barnett",
      "userId": "00179978372066039901"
     },
     "user_tz": -600
    },
    "id": "ORt4gNqIyJyV"
   },
   "outputs": [],
   "source": [
    "clean_df.to_csv(meta_data_filepath.replace(\".csv\",\"_clean.csv\"),index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPU7Ck/bUDeRx5ZARnAwfW5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
