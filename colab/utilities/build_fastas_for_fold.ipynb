{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16834,
     "status": "ok",
     "timestamp": 1726556768248,
     "user": {
      "displayName": "Alexander Barnett",
      "userId": "00179978372066039901"
     },
     "user_tz": -600
    },
    "id": "juhJIu39UeOG",
    "outputId": "69c055bf-d57b-487a-ed51-e455f72aa910"
   },
   "outputs": [],
   "source": [
    "%pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113158,
     "status": "ok",
     "timestamp": 1726557221483,
     "user": {
      "displayName": "Alexander Barnett",
      "userId": "00179978372066039901"
     },
     "user_tz": -600
    },
    "id": "SnS7Kgi7Ur62",
    "outputId": "55d7aaa3-d60f-4aae-e8c0-81ba3676bcd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Existing generation metadata read in.\n"
     ]
    }
   ],
   "source": [
    "#This metadata contains all the fasta files with sequence-redesigns for our backbone models\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import re\n",
    "import torch\n",
    "from time import time\n",
    "\n",
    "meta_data_filepath = \"/content/drive/MyDrive/Generative_Models/utilities/metadata_mpnn.csv\"\n",
    "\n",
    "if os.path.exists(meta_data_filepath):\n",
    "  #This metadata contains all the fasta files with sequence-redesigns for our backbone models\n",
    "  mpnn_metadata = pd.read_csv(meta_data_filepath)\n",
    "  print(\"Existing MPNN metadata read in.\")\n",
    "\n",
    "root_dir = \"/content/drive/MyDrive/Generative_Models/unconditional_generation/\"\n",
    "paths = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "  for filename in filenames:\n",
    "      if \"generation_metadata\" in filename:\n",
    "          paths.append(os.path.join(dirpath, filename))\n",
    "\n",
    "import pandas as pd\n",
    "all_dfs = []\n",
    "for file_path in paths:\n",
    "  df = pd.read_csv(file_path)\n",
    "  df[\"dir_path\"] = \"/\".join(file_path.split(\"/\")[:-1])\n",
    "  all_dfs.append(df)\n",
    "gen_meta = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "gen_meta = gen_meta[(gen_meta['entity_id'].notnull()) & ~(gen_meta['task'].str.contains('backbone'))]\n",
    "gen_meta['length'] = None\n",
    "gen_meta.loc[:,\"length\"] = gen_meta.loc[:,\"conditions\"].str.extract('(\\d+)')[0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SAW5FOtZcF7"
   },
   "outputs": [],
   "source": [
    "root_dir = \"/content/drive/MyDrive/Generative_Models/unconditional_generation/\"\n",
    "paths = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "  for filename in filenames:\n",
    "      if \"length_dist\" in filename:\n",
    "          paths.append(os.path.join(dirpath, filename))\n",
    "all_length_dists = {}\n",
    "for file_path in paths:\n",
    "  with open(file_path, \"r\") as f:\n",
    "    all_length_dists[file_path.split('/')[-1]] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2078379,
     "status": "ok",
     "timestamp": 1723174112294,
     "user": {
      "displayName": "Alexander Barnett",
      "userId": "00179978372066039901"
     },
     "user_tz": -600
    },
    "id": "fLlzHPaZFy3H",
    "outputId": "49f7b23a-d4c7-476a-8e18-8f35690531fa"
   },
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser\n",
    "from Bio.PDB import MMCIFParser\n",
    "from Bio.PDB.Polypeptide import PPBuilder\n",
    "\n",
    "import warnings\n",
    "from Bio.PDB.PDBExceptions import PDBConstructionWarning\n",
    "from Bio.SeqUtils import seq1\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "#warnings.resetwarnings()\n",
    "warnings.simplefilter('ignore', PDBConstructionWarning)\n",
    "\n",
    "def is_valid_protein(sequence):\n",
    "  try:\n",
    "    Seq(str(sequence))\n",
    "    return True\n",
    "  except ValueError:\n",
    "    return False\n",
    "\n",
    "for length in range(151,201):\n",
    "  mpnn_meta = mpnn_metadata.loc[mpnn_metadata.length == length].drop_duplicates(subset='output_file_path', keep='last')\n",
    "  #All foldingdiff outputs > 128 in length are actually just 128 so we'll ignore them\n",
    "  mpnn_meta = mpnn_meta.loc[~((mpnn_meta['length'] > 128) & (mpnn_meta['gen_model'] == 'foldingdiff'))]\n",
    "  #mpnn_meta.groupby('gen_model')['entity_id'].nunique()\n",
    "  records = []\n",
    "  for _, row in mpnn_meta.iterrows():\n",
    "    for i, design in enumerate(SeqIO.parse(row['output_file_path'], \"fasta\")):\n",
    "      if i > 0:\n",
    "        design.description = \"\"\n",
    "        design.name = \"\"\n",
    "        records.append(design)\n",
    "        #len(records)\n",
    "\n",
    "  sequence_outputs = gen_meta.loc[(gen_meta.task == \"sequence_generation\") & (gen_meta.length == length),:]\n",
    "  #LLM outputs sometimes have artifacts. Correct these first.\n",
    "  #empty characters/tokens\n",
    "  sequence_outputs.loc[:,'generated_sequence'] = sequence_outputs.loc[:,'generated_sequence'].apply(lambda x: re.sub(r'[\\s\\d]+', '', str(x)))\n",
    "  #recalc length\n",
    "  sequence_outputs.loc[:,'length'] = sequence_outputs.loc[:,'generated_sequence'].apply(lambda x: len(x))\n",
    "  #is a valid protein seq\n",
    "  sequence_outputs.loc[:,'generated_sequence'] = sequence_outputs.loc[sequence_outputs.loc[:,'generated_sequence'].apply(is_valid_protein),:]\n",
    "  sequence_outputs.drop('conditions',inplace=True, axis=1)\n",
    "\n",
    "  #now we need to subsample the LLM outputs (have overgenerated particularly at shorter lengths as there is not always length control)\n",
    "\n",
    "  length_dists = [\n",
    "  ('rita_xl','/content/drive/MyDrive/Generative_Models/unconditional_generation/rita_unconditional/uniref50_length_dist_rita.json'),\n",
    "  ('evodiff_OA_DM_640M','/content/drive/MyDrive/Generative_Models/unconditional_generation/evodiff_unconditional/uniref50_length_dist_evodiff.json'),\n",
    "  ('protgpt2','/content/drive/MyDrive/Generative_Models/unconditional_generation/protgpt2_unconditional/uniref50_length_dist_protgpt2.json'),\n",
    "  ('ESM_Design','/content/drive/MyDrive/Generative_Models/unconditional_generation/esmdesign_unconditional/uniref50_length_dist_esmdesign.json'),\n",
    "  ('ProGen2','/content/drive/MyDrive/Generative_Models/unconditional_generation/progen2_unconditional/uniref50_length_dist_progen2.json')]\n",
    "\n",
    "  seq_subsamp = pd.DataFrame()\n",
    "  for model, dist in length_dists:\n",
    "    print(model)\n",
    "    with open(dist, \"r\") as f:\n",
    "      uniprot_length_dist =  json.load(f)\n",
    "    uniprot_length_dist = [i for i in uniprot_length_dist if i[0] == length]\n",
    "    print(uniprot_length_dist)\n",
    "    sampled_df = pd.DataFrame()\n",
    "    sampled_df = sequence_outputs.loc[sequence_outputs.model == model].sample(frac=1, random_state=42).reset_index(drop=True).head(uniprot_length_dist[0][1])\n",
    "    if len(sampled_df) < uniprot_length_dist[0][1]:\n",
    "        print(f\"Warning: Only {len(sampled_df)} rows available for length {length}. Sampling all available rows.\")\n",
    "    seq_subsamp =  pd.concat([seq_subsamp, sampled_df])\n",
    "  seq_subsamp.reset_index(drop=True,inplace=True)\n",
    "\n",
    "  for i, row in seq_subsamp.iterrows():\n",
    "    id = row['model'] + \"_\" + \"len\"+ str(row[\"length\"]) +\"_\" +row['entity_id']\n",
    "    sequence = row['generated_sequence']\n",
    "    record = SeqIO.SeqRecord(\n",
    "        seq=Seq(sequence),\n",
    "        id=id,\n",
    "        description=\"\",\n",
    "        name=\"\",\n",
    "    )\n",
    "    records.append(record)\n",
    "  #len(records)\n",
    "\n",
    "  #Now we also need the sequences for our all-atom outputs so we can refold them\n",
    "  aa_outputs = gen_meta.loc[(gen_meta.task == \"all_atom_pdb_generation\") & (gen_meta.length == length),:]\n",
    "  #aa_outputs.groupby('model')['entity_id'].nunique()\n",
    "  roots = [\"/content/drive/MyDrive/Generative_Models/unconditional_generation/chroma_unconditional\",\n",
    "  \"/content/drive/MyDrive/Generative_Models/unconditional_generation/proteingenerator_unconditional\",\n",
    "  \"/content/drive/MyDrive/Generative_Models/unconditional_generation/protpardelle_unconditional\"]\n",
    "  for root in roots:\n",
    "    for i, row in aa_outputs.iterrows():\n",
    "      #print(root + \"/\" + row[\"output_file_name\"])\n",
    "      if os.path.exists(root + \"/\" + row[\"output_file_name\"]):\n",
    "        if root.split(\"/\")[-1] == \"chroma_unconditional\":\n",
    "          parser = MMCIFParser()\n",
    "          structure = parser.get_structure('cif', root + \"/\" + row[\"output_file_name\"])\n",
    "        else:\n",
    "          parser = PDBParser()\n",
    "          structure = parser.get_structure('pdb', root + \"/\" + row[\"output_file_name\"])\n",
    "        ppb=PPBuilder()\n",
    "        sequence = \"\"\n",
    "        for pp in ppb.build_peptides(structure):\n",
    "          sequence = sequence + pp.get_sequence()\n",
    "        if row[\"length\"] != len(sequence):\n",
    "          print(root + \"/\" + row[\"output_file_name\"])\n",
    "          print(len(sequence))\n",
    "          sequence=\"\"\n",
    "          for model in structure:\n",
    "            for chain in model:\n",
    "              for residue in chain:\n",
    "                res_name = residue.get_resname()\n",
    "                sequence += seq1(res_name)\n",
    "          if row[\"length\"] == len(sequence):\n",
    "            record = SeqIO.SeqRecord(\n",
    "            seq=Seq(sequence),\n",
    "            id=row['model'] + \"_\" + \"len\"+ str(row[\"length\"]) +\"_\" +row['entity_id'] + \"_refold\",\n",
    "            description=\"\",\n",
    "            name=\"\",)\n",
    "            records.append(record)\n",
    "          else:\n",
    "            print(\"is still busted ^^^\")\n",
    "        else:\n",
    "          record = SeqIO.SeqRecord(\n",
    "          seq=Seq(sequence),\n",
    "          id=row['model'] + \"_\" + \"len\"+ str(row[\"length\"]) +\"_\" +row['entity_id'],\n",
    "          description=\"\",\n",
    "          name=\"\",)\n",
    "          records.append(record)\n",
    "  with open(f'/content/drive/MyDrive/Generative_Models/utilities/fold_inputs/all_len{length}.fa', 'w',) as f:\n",
    "    SeqIO.write(records, f, 'fasta')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPUb/GItJ/GfqUMdl86w57x",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
