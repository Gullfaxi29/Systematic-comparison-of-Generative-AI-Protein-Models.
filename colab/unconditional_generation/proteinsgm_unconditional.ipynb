{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dhg4nTUdJTTo"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","!chmod +x Miniconda3-latest-Linux-x86_64.sh\n","!./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n","!git clone https://gitlab.com/mjslee0921/proteinsgm.git\n","\n","# Alternatively to the VVVV CODE BELOW VVV we can save this environment to drive and just unzip it for quicker set up\n","# Unzip the contents of the archive directly into /usr/local/envs/\n","#!tar -xzvf /content/drive/MyDrive/Generative_Models/envs/proteinsgm.tar.gz -C /usr/local/envs/ >/dev/null 2>&1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JP4bBmSoq_5T"},"outputs":[],"source":["%cd ./proteinsgm\n","!conda env create -f env.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FxIfqvQQ0nG0"},"outputs":[],"source":["%%bash\n","source activate proteinsgm\n","conda uninstall pytorch -y\n","conda uninstall cudatoolkit -y\n","conda install cudatoolkit==11.8 -y\n","conda install pytorch torchvision torchaudio pytorch-cuda=11.8 cuda=11.8 -c pytorch -c nvidia -y\n","conda clean --all -y"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HddjM2f1YgmU"},"outputs":[],"source":["#If you want to save the environment for quick access in the future\n","#!tar -czvf /content/proteinsgm.tar.gz -C /usr/local/envs/ .\n","#!mv /content/proteinsgm.tar.gz /content/drive/MyDrive/Generative_Models/envs/proteinsgm.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":389,"status":"ok","timestamp":1715039271374,"user":{"displayName":"Alexander Barnett","userId":"00179978372066039901"},"user_tz":-600},"id":"MRC6rfLC1102","outputId":"5dfb52cf-eb4e-470c-eb8a-407491e42b16"},"outputs":[],"source":["%cd ./proteinsgm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12364,"status":"ok","timestamp":1715218964436,"user":{"displayName":"Alexander Barnett","userId":"00179978372066039901"},"user_tz":-600},"id":"PDAKFhTxmQ65","outputId":"237d9b73-96b2-4538-bbb1-ebe5c08e41d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Existing generation metadata read in.\n","Loaded length distribution from drive\n"]}],"source":["drive.mount('/content/drive')\n","import os\n","import shutil\n","import glob\n","import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import uuid\n","from datetime import datetime\n","import re\n","import torch\n","import time\n","\n","meta_data_filepath = \"/content/drive/MyDrive/Generative_Models/unconditional_generation/proteinsgm_unconditional/generation_metadata_proteinsgm.csv\"\n","\n","if os.path.exists(meta_data_filepath):\n","  all_metadata_df = pd.read_csv(meta_data_filepath)\n","  print(\"Existing generation metadata read in.\")\n","else:\n","  all_metadata_df = pd.DataFrame()\n","  #all_metadata_df.to_csv(meta_data_filepath, index=False)\n","  print(\"Created generation metadata dataframe\")\n","\n","\n","len_dist_filepath = \"/content/drive/MyDrive/Generative_Models/unconditional_generation/proteinsgm_unconditional/uniref50_length_dist_proteinsgm.json\"\n","\n","if os.path.exists(len_dist_filepath):\n","  with open(len_dist_filepath, \"r\") as f:\n","    uniprot_length_dist =  json.load(f)\n","  print(\"Loaded length distribution from drive\")\n","else:\n","\n","  #https://www.uniprot.org/uniprotkb/statistics#sequence-size\n","  bins = np.array([13,51,101,151,201,251,301,351,401,451,501,551,601,651,701,751,801,851,901,951,1001,1101,1201,1301,1401,1501,1601,1701,1801,1901,2001,2101,2201,2301,2401,2501,34350])\n","  swissprot_reviewed = np.array([0,9968,43534,59796,59574,58452,52413,52846,45901,37706,30572,22287,15830,13156,9403,7870,5700,4889,5301,4109,3007,4124,2897,2207,2070,1675,834,642,587,503,395,272,386,340,234,195,1462])\n","  TrEMBL_unreviewed = np.array([0,2668805,19825275,24705701,23838128,23462438,23225451,21389271,16814580,14287105,11501843,8283150,6266068,4715059,3755005,3186452,2687314,2166878,1843669,1457871,1153537,1975953,1398765,961048,664766,517536,390552,300984,236895,210921,180246,138808,122833,102865,82441,71548,527646])\n","\n","  ecdf = np.cumsum(swissprot_reviewed) / np.sum(swissprot_reviewed)\n","  #shortest protein in uniprot is 14 res, longest is 34350 res.\n","  x = np.arange(14, 34350+1)\n","  ecdf = np.interp(x, bins, ecdf)\n","\n","  # Sample from the empirical CDF\n","  num_samples = 11000\n","  random_values = np.random.rand(num_samples)\n","  sampled_lengths = np.round(np.interp(random_values, ecdf, x)).astype(int)\n","  #ten thousand sequences up to 1000 res in length\n","  sampled_lengths = sampled_lengths[sampled_lengths <= 1000][0:10000]\n","\n","  # Plot the histogram of sampled values\n","  hist_values, bin_edges, patches = plt.hist(sampled_lengths, bins=x[0:1001-13], alpha=0.7, label='Sampled Values')\n","  plt.xlabel('X-axis label')\n","  plt.ylabel('Frequency')\n","  plt.legend()\n","  plt.show()\n","\n","  uniprot_length_dist = list(zip([int(edge) for edge in bin_edges],[int(value) for value in hist_values]))\n","  with open(len_dist_filepath, \"w\") as f:\n","      json.dump(uniprot_length_dist, f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VCnHvt18_Gfl"},"outputs":[],"source":["def make_generation_command(length,batch_size):\n","  return f\"\"\"\n","source activate proteinsgm\n","python -c '\n","\n","import torch\n","torch.cuda.set_device(0)\n","torch.set_default_tensor_type(torch.cuda.FloatTensor)\n","\n","import numpy as np\n","from pathlib import Path\n","from score_sde_pytorch.utils import get_model, restore_checkpoint, recursive_to\n","from score_sde_pytorch.models.ema import ExponentialMovingAverage\n","import score_sde_pytorch.sde_lib as sde_lib\n","import score_sde_pytorch.sampling as sampling\n","import score_sde_pytorch.losses as losses\n","import pickle as pkl\n","import argparse\n","import yaml\n","from easydict import EasyDict\n","from tqdm.auto import tqdm\n","from utils import get_conditions_random, get_mask_all_lengths, get_conditions_from_pdb\n","import time\n","\n","torch.cuda.set_device(0)\n","torch.set_default_tensor_type(torch.cuda.FloatTensor)\n","\n","with open(\"./configs/cond_length.yml\", \"r\") as f:\n","        config = EasyDict(yaml.safe_load(f))\n","config.device = \"cuda\"\n","\n","workdir = Path(\"sampling\", \"coords_6d\", Path(\"./configs/cond_length.yml\").stem, Path(\"./checkpoints/cond_length.pth\").stem, \"len_\"+ str({length}))\n","\n","\n","score_model = get_model(config)\n","ema = ExponentialMovingAverage(score_model.parameters(), decay=config.model.ema_rate)\n","optimizer = losses.get_optimizer(config, score_model.parameters())\n","state = dict(optimizer=optimizer, model=score_model, ema=ema, step=0)\n","state = restore_checkpoint(\"./checkpoints/cond_length.pth\", state, \"cuda\")\n","state[\"ema\"].store(state[\"model\"].parameters())\n","state[\"ema\"].copy_to(state[\"model\"].parameters())\n","print(\"Start time \" + str(time.time()))\n","\n","if config.training.sde == \"vesde\":\n","    sde = sde_lib.VESDE(sigma_min=config.model.sigma_min, sigma_max=config.model.sigma_max,\n","                        N=config.model.num_scales)\n","    sampling_eps = 1e-5\n","elif config.training.sde == \"vpsde\":\n","    sde = sde_lib.VPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n","    sampling_eps = 1e-3\n","\n","sampling_shape = ({batch_size}, config.data.num_channels,\n","                      config.data.max_res_num, config.data.max_res_num)\n","\n","sampling_fn = sampling.get_sampling_fn(config, sde, sampling_shape, sampling_eps)\n","\n","generated_samples = []\n","\n","for _ in tqdm(range(1)):\n","  mask = get_mask_all_lengths(config,batch_size={batch_size})[{length}-40]\n","  condition = {{\"length\": mask.to(config.device)}}\n","  sample, n = sampling_fn(state[\"model\"], condition)\n","  generated_samples.append(sample.cpu())\n","\n","workdir.mkdir(parents=True, exist_ok=True)\n","with open(workdir.joinpath(\"len_\"+ str({length})+\".pkl\"), \"wb\") as f:\n","  pkl.dump(generated_samples, f)\n","print(\"End time \" + str(time.time()))\n","'\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i0cw7GvrCwZE"},"outputs":[],"source":["\n","#This is for the initial gneration which creates single outputs per batch, these are then run through rosetta minimisations in the lower part of the notebook\n","import time\n","for length, batch_size in uniprot_length_dist:\n","  if batch_size == 0: continue\n","  if length <40: continue\n","  if length > 128: continue\n","  if all_metadata_df.loc[(all_metadata_df.conditions == \"length = \" + str(length)) & (all_metadata_df.gpu == \"T4 GPU\"),:].shape[0] >= 1: continue\n","\n","  cleanup_command = f\"\"\"\n","  for file in /content/proteinsgm/sampling/coords_6d/cond_length/cond_length/len_{length}/*\n","  do\n","    bn=$(basename \"$file\")\n","    mv $file /content/drive/MyDrive/Generative_Models/unconditional_generation/proteinsgm_unconditional/$bn\n","  done\n","  rm -rf /content/proteinsgm/sampling\n","  \"\"\"\n","  generation_command = make_generation_command(length, batch_size)\n","  meta_data = {}\n","  meta_data['batch_id'] = str(uuid.uuid4())\n","  meta_data['batch_size'] = str(batch_size)\n","  meta_data['Timestamp'] = str(datetime.now())\n","  meta_data['model'] = 'ProteinSGM'\n","  meta_data['task'] = 'backbone generation (6D)'\n","  meta_data['conditions'] = 'length = ' + str(length)\n","  meta_data['gpu'] = 'T4 GPU'\n","  start_time = time.time()\n","  !{generation_command}\n","  end_time = time.time()\n","  total_job_time = end_time - start_time\n","  meta_data['wall_time_batch'] = str(total_job_time) + \" Seconds\"\n","  meta_data['wall_time_task'] = str(total_job_time/batch_size) + \" Seconds (inferred)\"\n","  for filename in os.listdir(\"/content/proteinsgm/sampling/coords_6d/cond_length/cond_length/len_\"+str(length)):\n","        meta_data['output_file_name'] = filename\n","        metadata_entry = pd.Series(meta_data)\n","        all_metadata_df = pd.concat([all_metadata_df,pd.DataFrame(metadata_entry).T], ignore_index=True)\n","\n","  all_metadata_df.to_csv(meta_data_filepath, index=False)\n","  print(\"Metadata saved. Cleaning up....\")\n","  !{cleanup_command}\n","  torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UqwyEOvgjF2-"},"outputs":[],"source":["#The rosetta minimasation step runs on the cpu so we'll do it as a seperate step (Disconnect and Reconnect runtime). It also doesn't require the huge conda environment we ended up with to get the 6D sampling to work.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82560,"status":"ok","timestamp":1717025429040,"user":{"displayName":"Alexander Barnett","userId":"00179978372066039901"},"user_tz":-600},"id":"tWvgNkcJl0hH","outputId":"5633c55b-7860-4c1c-951d-43694a20ff76"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","!chmod +x Miniconda3-latest-Linux-x86_64.sh\n","!./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n","!git clone https://gitlab.com/mjslee0921/proteinsgm.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67191,"status":"ok","timestamp":1717025980151,"user":{"displayName":"Alexander Barnett","userId":"00179978372066039901"},"user_tz":-600},"id":"tZAmL5fnl5KC","outputId":"da8ec607-e201-4d05-9d25-cdb553cd3ded"},"outputs":[],"source":["%cd ./proteinsgm\n","!conda env create -f env.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0xomt1fmAp7"},"outputs":[],"source":["drive.mount('/content/drive')\n","import os\n","import shutil\n","import glob\n","import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import uuid\n","from datetime import datetime\n","import re\n","import torch\n","import time\n","\n","meta_data_filepath = \"/content/drive/MyDrive/Generative_Models/unconditional_generation/proteinsgm_unconditional/generation_metadata_proteinsgm.csv\"\n","\n","if os.path.exists(meta_data_filepath):\n","  all_metadata_df = pd.read_csv(meta_data_filepath)\n","  print(\"Existing generation metadata read in.\")\n","else:\n","  all_metadata_df = pd.DataFrame()\n","  #all_metadata_df.to_csv(meta_data_filepath, index=False)\n","  print(\"Created generation metadata dataframe\")\n","\n","\n","len_dist_filepath = \"/content/drive/MyDrive/Generative_Models/unconditional_generation/proteinsgm_unconditional/uniref50_length_dist_proteinsgm.json\"\n","\n","if os.path.exists(len_dist_filepath):\n","  with open(len_dist_filepath, \"r\") as f:\n","    uniprot_length_dist =  json.load(f)\n","  print(\"Loaded length distribution from drive\")\n","else:\n","\n","  #https://www.uniprot.org/uniprotkb/statistics#sequence-size\n","  bins = np.array([13,51,101,151,201,251,301,351,401,451,501,551,601,651,701,751,801,851,901,951,1001,1101,1201,1301,1401,1501,1601,1701,1801,1901,2001,2101,2201,2301,2401,2501,34350])\n","  swissprot_reviewed = np.array([0,9968,43534,59796,59574,58452,52413,52846,45901,37706,30572,22287,15830,13156,9403,7870,5700,4889,5301,4109,3007,4124,2897,2207,2070,1675,834,642,587,503,395,272,386,340,234,195,1462])\n","  TrEMBL_unreviewed = np.array([0,2668805,19825275,24705701,23838128,23462438,23225451,21389271,16814580,14287105,11501843,8283150,6266068,4715059,3755005,3186452,2687314,2166878,1843669,1457871,1153537,1975953,1398765,961048,664766,517536,390552,300984,236895,210921,180246,138808,122833,102865,82441,71548,527646])\n","\n","  ecdf = np.cumsum(swissprot_reviewed) / np.sum(swissprot_reviewed)\n","  #shortest protein in uniprot is 14 res, longest is 34350 res.\n","  x = np.arange(14, 34350+1)\n","  ecdf = np.interp(x, bins, ecdf)\n","\n","  # Sample from the empirical CDF\n","  num_samples = 11000\n","  random_values = np.random.rand(num_samples)\n","  sampled_lengths = np.round(np.interp(random_values, ecdf, x)).astype(int)\n","  #ten thousand sequences up to 1000 res in length\n","  sampled_lengths = sampled_lengths[sampled_lengths <= 1000][0:10000]\n","\n","  # Plot the histogram of sampled values\n","  hist_values, bin_edges, patches = plt.hist(sampled_lengths, bins=x[0:1001-13], alpha=0.7, label='Sampled Values')\n","  plt.xlabel('X-axis label')\n","  plt.ylabel('Frequency')\n","  plt.legend()\n","  plt.show()\n","\n","  uniprot_length_dist = list(zip([int(edge) for edge in bin_edges],[int(value) for value in hist_values]))\n","  with open(len_dist_filepath, \"w\") as f:\n","      json.dump(uniprot_length_dist, f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"J4HKIoTZvXZC"},"outputs":[],"source":["def make_minimisation_command(data,length,index):\n","  return f\"\"\"\n","source activate proteinsgm\n","python -c '\n","\n","import math\n","import numpy as np\n","from pathlib import Path\n","import pickle as pkl\n","from pyrosetta import *\n","import rosetta_min.run as rosetta\n","import argparse\n","import time\n","\n","#Arguments\n","data = {data}\n","tag=\"len_\"+ str({length})\n","index={index}\n","mask_info=\"1:5,10:15\"\n","n_iter=10\n","dist_std=2\n","angle_std=20\n","fastdesign=False\n","fastrelax=False\n","\n","outPath = Path(\"sampling\", \"rosetta\", tag,str(Path(data).parent.stem)+\"_index_\"+str(index))\n","with open(data, \"rb\") as f:\n","  samples = pkl.load(f)[0] #for some reason had to alter this to take one-and-only object from pickle\n","sample = samples[index]\n","msk = np.round(sample[-1])\n","L = math.sqrt(len(msk[msk == 1]))\n","if not (L).is_integer():\n","  raise ValueError(\"Terminated due to improper masking channel...\")\n","else:\n","  L = int(L)\n","\n","# Initialize sequence of polyalanines and gather constraints\n","seq = \"A\" * L\n","pose = None\n","\n","npz = {{}}\n","for idx, name in enumerate([\"dist\", \"omega\", \"theta\", \"phi\"]):\n","  npz[name] = np.clip(sample[idx][msk == 1].reshape(L, L), -1, 1)\n","\n","npz[\"dist_abs\"] = (npz[\"dist\"] + 1) * 10\n","npz[\"omega_abs\"] = npz[\"omega\"] * math.pi\n","npz[\"theta_abs\"] = npz[\"theta\"] * math.pi\n","npz[\"phi_abs\"] = (npz[\"phi\"] + 1) * math.pi / 2\n","\n","rosetta.init_pyrosetta()\n","\n","for n in range(n_iter):\n","  outPath_run = outPath.joinpath(\"round_\"+str(n + 1))\n","  if outPath_run.joinpath(\"final_structure.pdb\").is_file():\n","      continue\n","\n","  _ = rosetta.run_minimization(\n","      npz,\n","      seq,\n","      pose=pose,\n","      scriptdir=Path(\"rosetta_min\"),\n","      outPath=outPath_run,\n","      angle_std=angle_std,  # Angular harmonic std\n","      dist_std=dist_std,  # Distance harmonic std\n","      use_fastdesign=fastdesign,\n","      use_fastrelax=fastrelax,\n","  )\n","\n","if fastdesign:\n","  score_fn = create_score_function(\"ref2015\").score\n","  filename = \"final_structure.pdb\" if fastrelax else \"structure_after_design.pdb\"\n","else:\n","  score_fn = ScoreFunction()\n","  score_fn.add_weights_from_file(str(Path(\"rosetta_min\").joinpath(\"data/scorefxn_cart.wts\")))\n","  filename = \"structure_before_design.pdb\"\n","\n","e_min = 9999\n","best_run = 0\n","for i in range(n_iter):\n","  pose = pose_from_pdb(str(outPath.joinpath(\"round_\"+str(i+1), filename)))\n","  e = score_fn(pose)\n","  if e < e_min:\n","    best_run = i\n","    e_min = e\n","\n","outPath.joinpath(f\"best_run\").symlink_to(outPath.joinpath(\"round_\"+str(best_run + 1)).resolve(),target_is_directory=True)\n","with open(outPath.joinpath(\"sample.pkl\"), \"wb\") as f:\n","  pkl.dump(sample, f)\n","'\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"D5yPpIuapO4t"},"outputs":[],"source":["import time\n","from collections import defaultdict\n","to_minimise = all_metadata_df.loc[all_metadata_df.task == \"backbone generation (6D)\",:]\n","to_minimise['length'] = to_minimise['conditions'].str.extract(r'(\\d+)').astype(int)\n","to_minimise = to_minimise.loc[(to_minimise.length<=128) & (to_minimise.length>=40),:].sort_values(by='Timestamp', ascending=False).drop_duplicates(subset='output_file_name', keep='first').reset_index(drop=True)\n","\n","already_done = all_metadata_df.loc[all_metadata_df.task == \"backbone generation (Rosetta)\",:]\n","already_done['length'] = already_done['conditions'].str.extract(r'(\\d+)').astype(int)\n","already_done = defaultdict(int, already_done.groupby('length').size().to_dict())\n","\n","for index,row in to_minimise.iterrows():\n","  length = row['length']\n","  batch_size = int(row['batch_size'])\n","  pickle = \"/content/drive/MyDrive/Generative_Models/unconditional_generation/proteinsgm_unconditional/\" + row['output_file_name']\n","  if batch_size == 0: continue\n","  print(pickle)\n","  for i in range(already_done[length],batch_size):\n","    print(\"generating \" + \"len\"+str(length)+\"_\"+str(i)+\".pdb .....\")\n","    cleanup_command = f\"\"\"\n","    for file in /content/proteinsgm/sampling/rosetta/len_{length}/proteinsgm_unconditional_index_{i}/round_10/*\n","    do\n","      bn=$(basename \"$file\")\n","      mv $file /content/drive/MyDrive/Generative_Models/unconditional_generation/proteinsgm_unconditional/$bn\n","    done\n","    rm -rf /content/proteinsgm/sampling\n","    \"\"\"\n","    minimisation_command = make_minimisation_command('\"'+pickle+'\"', length, i)\n","    meta_data = {}\n","    meta_data['batch_id'] = None\n","    meta_data['batch_size'] = None\n","    meta_data['Timestamp'] = str(datetime.now())\n","    meta_data['model'] = 'ProteinSGM'\n","    meta_data['task'] = 'backbone generation (Rosetta)'\n","    meta_data['conditions'] = 'length = ' + str(length)\n","    meta_data['gpu'] = 'CPU'\n","    start_time = time.time()\n","    !{minimisation_command}\n","    end_time = time.time()\n","    total_job_time = end_time - start_time\n","    meta_data['wall_time_task'] = str(total_job_time) + \" Seconds\"\n","    for filename in os.listdir(\"/content/proteinsgm/sampling/rosetta/len_\"+str(length)+\"/proteinsgm_unconditional_index_\" + str(i) + \"/round_10/\"):\n","      meta_data['entity_id'] = str(uuid.uuid4())\n","      new_file_name = \"ProteinSGM_len\" + str(length) + \"_\" + meta_data['entity_id'] + \".pdb\n","      shutil.move(\"/content/proteinsgm/sampling/rosetta/len_\"+str(length)+\"/proteinsgm_unconditional_index_\" + str(i) + \"/round_10/\" + filename,\"/content/proteinsgm/sampling/rosetta/len_\"+str(length)+\"/proteinsgm_unconditional_index_\" + str(i) + \"/round_10/\" + new_file_name)\n","      meta_data['output_file_name'] = new_file_name\n","      metadata_entry = pd.Series(meta_data)\n","      all_metadata_df = pd.concat([all_metadata_df,pd.DataFrame(metadata_entry).T], ignore_index=True)\n","    all_metadata_df.to_csv(meta_data_filepath, index=False)\n","    print(\"Metadata saved. Cleaning up....\")\n","    !{cleanup_command}"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPiMQhjHj1Otnwe+AopQy1R","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
