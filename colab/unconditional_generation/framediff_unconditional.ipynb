{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48438,"status":"ok","timestamp":1713417796253,"user":{"displayName":"Alexander Barnett","userId":"00179978372066039901"},"user_tz":-600},"id":"0oTjpdSJ5XYq","outputId":"f7d98b8f-bc6f-47ed-f809-90dd2297bfab"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-04-18 05:22:28--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.32.241, 104.16.191.158, 2606:4700::6810:bf9e, ...\n","Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.32.241|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 143351488 (137M) [application/octet-stream]\n","Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n","\n","Miniconda3-latest-L 100%[===================>] 136.71M   189MB/s    in 0.7s    \n","\n","2024-04-18 05:22:29 (189 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [143351488/143351488]\n","\n","PREFIX=/usr/local\n","Unpacking payload ...\n","\n","Installing base environment...\n","\n","Preparing transaction: ...working... done\n","Executing transaction: ...working... done\n","installation finished.\n","WARNING:\n","    You currently have a PYTHONPATH environment variable set. This may cause\n","    unexpected behavior when running the Python interpreter in Miniconda3.\n","    For best results, please verify that your PYTHONPATH only points to\n","    directories of packages that are compatible with the Python interpreter\n","    in Miniconda3: /usr/local\n","Cloning into 'se3_diffusion'...\n","remote: Enumerating objects: 1011, done.\u001b[K\n","remote: Counting objects: 100% (129/129), done.\u001b[K\n","remote: Compressing objects: 100% (54/54), done.\u001b[K\n","remote: Total 1011 (delta 96), reused 75 (delta 75), pack-reused 882\u001b[K\n","Receiving objects: 100% (1011/1011), 274.65 MiB | 32.84 MiB/s, done.\n","Resolving deltas: 100% (381/381), done.\n"]}],"source":[" from google.colab import drive\n","drive.mount('/content/drive')\n","!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","!chmod +x Miniconda3-latest-Linux-x86_64.sh\n","!./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n","!git clone https://github.com/jasonkyuyim/se3_diffusion"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"F8_J-49E5h4e"},"outputs":[],"source":["%cd ./se3_diffusion\n","!conda env create -f se3.yml"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eMjkGZgR5jgO","outputId":"8ffe4ac4-61b8-401c-e5d8-1535a0e3d3e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Obtaining file:///content/se3_diffusion\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Installing collected packages: se3-diffusion\n","  Running setup.py develop for se3-diffusion\n","Successfully installed se3-diffusion-0.0.0\n"]},{"name":"stderr","output_type":"stream","text":["WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"]}],"source":["%%bash\n","source activate se3\n","pip install -e ./"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mpIHHWbfQO-_"},"outputs":[],"source":["#God knows why, but this suddenly started having cuda problems. Seems to be fixed by uninstalling and reinstalling torch packages\n","%%bash\n","source activate se3\n","conda uninstall pytorch torchvision torchaudio pytorch-cuda"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BTzP6rVQqBPl"},"outputs":[],"source":["%%bash\n","source activate se3\n","conda install pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda=11.6 -c pytorch -c nvidia"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62081,"status":"ok","timestamp":1713417705719,"user":{"displayName":"Alexander Barnett","userId":"00179978372066039901"},"user_tz":-600},"id":"QSn1NN7ysWbS","outputId":"c6787e62-8a4c-4ecf-af48-6cf0fce8fbd0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Existing generation metadata read in.\n","Loaded length distribution from drive\n"]}],"source":["import os\n","import shutil\n","import glob\n","import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import uuid\n","from datetime import datetime\n","import re\n","import torch\n","from time import time\n","\n","meta_data_filepath = \"/content/drive/MyDrive/Generative_Models/unconditional_generation/framediff_unconditional/generation_metadata_framediff.csv\"\n","\n","if os.path.exists(meta_data_filepath):\n","  all_metadata_df = pd.read_csv(meta_data_filepath)\n","  print(\"Existing generation metadata read in.\")\n","else:\n","  all_metadata_df = pd.DataFrame()\n","  #all_metadata_df.to_csv(meta_data_filepath, index=False)\n","  print(\"Created generation metadata dataframe\")\n","\n","\n","len_dist_filepath = \"/content/drive/MyDrive/Generative_Models/unconditional_generation/framediff_unconditional/uniref50_length_dist_framediff.json\"\n","\n","if os.path.exists(len_dist_filepath):\n","  with open(len_dist_filepath, \"r\") as f:\n","    uniprot_length_dist =  json.load(f)\n","  print(\"Loaded length distribution from drive\")\n","else:\n","\n","  #https://www.uniprot.org/uniprotkb/statistics#sequence-size\n","  bins = np.array([13,51,101,151,201,251,301,351,401,451,501,551,601,651,701,751,801,851,901,951,1001,1101,1201,1301,1401,1501,1601,1701,1801,1901,2001,2101,2201,2301,2401,2501,34350])\n","  swissprot_reviewed = np.array([0,9968,43534,59796,59574,58452,52413,52846,45901,37706,30572,22287,15830,13156,9403,7870,5700,4889,5301,4109,3007,4124,2897,2207,2070,1675,834,642,587,503,395,272,386,340,234,195,1462])\n","  TrEMBL_unreviewed = np.array([0,2668805,19825275,24705701,23838128,23462438,23225451,21389271,16814580,14287105,11501843,8283150,6266068,4715059,3755005,3186452,2687314,2166878,1843669,1457871,1153537,1975953,1398765,961048,664766,517536,390552,300984,236895,210921,180246,138808,122833,102865,82441,71548,527646])\n","\n","  ecdf = np.cumsum(swissprot_reviewed) / np.sum(swissprot_reviewed)\n","  #shortest protein in uniprot is 14 res, longest is 34350 res.\n","  x = np.arange(14, 34350+1)\n","  ecdf = np.interp(x, bins, ecdf)\n","\n","  # Sample from the empirical CDF\n","  num_samples = 11000\n","  random_values = np.random.rand(num_samples)\n","  sampled_lengths = np.round(np.interp(random_values, ecdf, x)).astype(int)\n","  #ten thousand sequences up to 1000 res in length\n","  sampled_lengths = sampled_lengths[sampled_lengths <= 1000][0:10000]\n","\n","  # Plot the histogram of sampled values\n","  hist_values, bin_edges, patches = plt.hist(sampled_lengths, bins=x[0:1001-13], alpha=0.7, label='Sampled Values')\n","  plt.xlabel('X-axis label')\n","  plt.ylabel('Frequency')\n","  plt.legend()\n","  plt.show()\n","\n","  uniprot_length_dist = list(zip([int(edge) for edge in bin_edges],[int(value) for value in hist_values]))\n","  with open(len_dist_filepath, \"w\") as f:\n","      json.dump(uniprot_length_dist, f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nv-8FKqruKpd"},"outputs":[],"source":["#because of the code structure we need to first save the metadata to a local copy and then transfer back\n","all_metadata_df.to_csv(\"./generation_metadata_framediff.csv\",index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6PFtnF7zs8Fm"},"outputs":[],"source":["generation_command = \"\"\"\n","\n","source activate se3\n","python -c '\n","\n","import torch\n","torch.set_default_tensor_type(torch.cuda.FloatTensor)\n","\n","import os\n","import shutil\n","import uuid\n","from datetime import datetime\n","import time\n","import tree\n","import numpy as np\n","import hydra\n","import subprocess\n","import logging\n","import pandas as pd\n","from datetime import datetime\n","from biotite.sequence.io import fasta\n","import GPUtil\n","from typing import Optional\n","import psutil\n","from analysis import utils as au\n","from analysis import metrics\n","from data import utils as du\n","from data import residue_constants\n","from typing import Dict\n","from experiments import train_se3_diffusion\n","from omegaconf import DictConfig, OmegaConf\n","from openfold.data import data_transforms\n","import esm\n","import experiments.inference_se3_diffusion as se3_inf\n","\n","@hydra.main(version_base=None, config_path=\"./config\", config_name=\"inference\")\n","def my_app(conf : DictConfig) -> None:\n","\n","  local_metadata = \"./generation_metadata_framediff.csv\"\n","  try:\n","    all_metadata_df = pd.read_csv(local_metadata)\n","  except pd.errors.EmptyDataError:\n","    all_metadata_df = pd.DataFrame()\n","\n","  torch.cuda.empty_cache()\n","  torch.cuda.set_device(0)\n","  torch.set_default_tensor_type(torch.cuda.FloatTensor)\n","  sampler = se3_inf.Sampler(conf)\n","  length = conf[\"inference\"][\"samples\"][\"max_length\"]\n","  batch_size = conf[\"inference\"][\"samples\"][\"samples_per_length\"]\n","\n","  meta_data = {}\n","  meta_data[\"batch_id\"] = None\n","  meta_data[\"batch_size\"] = None\n","  meta_data[\"Timestamp\"] = str(datetime.now())\n","  meta_data[\"model\"] = \"FrameDiff\"\n","  meta_data[\"task\"] = \"backbone_pdb_generation\"\n","  meta_data[\"conditions\"] = \"length = \" + str(int(length))\n","  meta_data[\"gpu\"] = \"T4 GPU\"\n","  #adapted from sampler.run_sampling() [excluding the protein mpnn part]\n","  all_sample_lengths = range(\n","            sampler._sample_conf.min_length,\n","            sampler._sample_conf.max_length+1,\n","            sampler._sample_conf.length_step\n","        )\n","  for sample_length in all_sample_lengths:\n","    print(\"LENGTH: \" + str(sample_length))\n","    length_dir = os.path.join(\n","        sampler._output_dir, f\"length_{sample_length}\")\n","    os.makedirs(length_dir, exist_ok=True)\n","    sampler._log.info(f\"Sampling length {sample_length}: {length_dir}\")\n","    print(sampler.device)\n","    for sample_i in range(sampler._sample_conf.samples_per_length):\n","      sample_dir = os.path.join(length_dir, f\"sample_{sample_i}\")\n","      if os.path.isdir(sample_dir):\n","          continue\n","      os.makedirs(sample_dir, exist_ok=True)\n","\n","      start_time = time.time()\n","      sample_output = sampler.sample(sample_length)\n","      traj_paths = sampler.save_traj(\n","          sample_output[\"prot_traj\"],\n","          sample_output[\"rigid_0_traj\"],\n","          np.ones(sample_length),\n","          output_dir=sample_dir\n","      )\n","      end_time = time.time()\n","      total_job_time = end_time - start_time\n","      meta_data[\"wall_time_batch\"] = None\n","      meta_data[\"wall_time_task\"] = str(total_job_time) + \" Seconds\"\n","      meta_data[\"entity_id\"] = str(uuid.uuid4())\n","      new_file_name = \"FrameDiff_len\" + str(length) + \"_\" + meta_data['entity_id] + \".pdb\"\n","      meta_data[\"output_file_name\"] = new_file_name\n","      shutil.move(sample_dir +\"/sample_1.pdb\", \"./\"+ new_file_name)\n","      metadata_entry = pd.Series(meta_data)\n","      all_metadata_df = all_metadata_df.append(metadata_entry, ignore_index=True)\n","\n","  all_metadata_df.to_csv(local_metadata, index=False)\n","\n","my_app()\n","'\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QBTxZeg1Rkb-"},"outputs":[],"source":["import yaml\n","with open(\"./config/inference.yaml\", 'r') as file:\n","        config = yaml.safe_load(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_2er8B3_RqIa"},"outputs":[],"source":["for length, batch_size in uniprot_length_dist:\n","  if os.path.exists(meta_data_filepath):\n","    all_metadata_df = pd.read_csv(meta_data_filepath)\n","  else:\n","    all_metadata_df = pd.DataFrame()\n","  if all_metadata_df.loc[all_metadata_df.conditions == \"length = \" + str(length),:].shape[0] >= batch_size: continue\n","\n","  config['inference']['samples']['max_length'] = length\n","  config['inference']['samples']['min_length'] = length\n","  config['inference']['samples']['name'] = \"len_\"+str(length)\n","  config['inference']['samples']['samples_per_length'] = batch_size\n","  with open(\"./config/inference.yaml\", 'w') as file:\n","    yaml.dump(config, file, default_flow_style=False)\n","\n","  !{generation_command}\n","  print(\"Metadata saved. Cleaning up....\")\n","  for pdb_file in glob.glob(\"*.pdb\"):\n","    file_basename = os.path.basename(pdb_file)\n","    shutil.copy(pdb_file, \"/content/drive/MyDrive/Generative_Models/unconditional_generation/framediff_unconditional/\" +file_basename)\n","  shutil.copy(\"./generation_metadata_framediff.csv\",meta_data_filepath)\n","  for pdb_file in glob.glob(\"*.pdb\"):\n","    os.remove(pdb_file)\n","  !rm -rf ./inference_outputs/*\n","  torch.cuda.empty_cache()\n","  print(\"Cleanup complete\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"umM4IVSlDU3l"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyPtGxInxuPTAQQEnbgPAd5z"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}