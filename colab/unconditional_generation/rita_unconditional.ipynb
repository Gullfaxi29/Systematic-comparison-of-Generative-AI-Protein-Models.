{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"66AX22MSrAXM"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","#RitaModelForCausalLM is not compatible with current versions of HuggingFace Transformers so we need to downgrade (~version at time of publishing)\n","!pip install transformers==4.19.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pohoqC0wh7-A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716938838555,"user_tz":-600,"elapsed":6239,"user":{"displayName":"Alex Barnett","userId":"15265383415858973830"}},"outputId":"7e449265-48e3-46bc-bd89-d39eb0e52287"},"outputs":[{"output_type":"stream","name":"stdout","text":["Existing generation metadata read in.\n","Loaded length distribution from drive\n"]}],"source":["import os\n","import shutil\n","import glob\n","import json\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import uuid\n","from datetime import datetime\n","import re\n","import torch\n","import time\n","\n","meta_data_filepath = \"/content/drive/MyDrive/Generative_Models/unconditional_generation/rita_unconditional/generation_metadata_rita.csv\"\n","\n","if os.path.exists(meta_data_filepath):\n","  all_metadata_df = pd.read_csv(meta_data_filepath)\n","  print(\"Existing generation metadata read in.\")\n","else:\n","  all_metadata_df = pd.DataFrame()\n","  #all_metadata_df.to_csv(meta_data_filepath, index=False)\n","  print(\"Created generation metadata dataframe\")\n","\n","len_dist_filepath = \"/content/drive/MyDrive/Generative_Models/unconditional_generation/rita_unconditional/uniref50_length_dist_rita.json\"\n","\n","if os.path.exists(len_dist_filepath):\n","  with open(len_dist_filepath, \"r\") as f:\n","    uniprot_length_dist =  json.load(f)\n","  print(\"Loaded length distribution from drive\")\n","else:\n","  #https://www.uniprot.org/uniprotkb/statistics#sequence-size\n","  bins = np.array([13,51,101,151,201,251,301,351,401,451,501,551,601,651,701,751,801,851,901,951,1001,1101,1201,1301,1401,1501,1601,1701,1801,1901,2001,2101,2201,2301,2401,2501,34350])\n","  swissprot_reviewed = np.array([0,9968,43534,59796,59574,58452,52413,52846,45901,37706,30572,22287,15830,13156,9403,7870,5700,4889,5301,4109,3007,4124,2897,2207,2070,1675,834,642,587,503,395,272,386,340,234,195,1462])\n","  TrEMBL_unreviewed = np.array([0,2668805,19825275,24705701,23838128,23462438,23225451,21389271,16814580,14287105,11501843,8283150,6266068,4715059,3755005,3186452,2687314,2166878,1843669,1457871,1153537,1975953,1398765,961048,664766,517536,390552,300984,236895,210921,180246,138808,122833,102865,82441,71548,527646])\n","\n","  ecdf = np.cumsum(swissprot_reviewed) / np.sum(swissprot_reviewed)\n","  #shortest protein in uniprot is 14 res, longest is 34350 res.\n","  x = np.arange(14, 34350+1)\n","  ecdf = np.interp(x, bins, ecdf)\n","\n","  # Sample from the empirical CDF\n","  num_samples = 11000\n","  random_values = np.random.rand(num_samples)\n","  sampled_lengths = np.round(np.interp(random_values, ecdf, x)).astype(int)\n","  #ten thousand sequences up to 1000 res in length\n","  sampled_lengths = sampled_lengths[sampled_lengths <= 1000][0:10000]\n","\n","  # Plot the histogram of sampled values\n","  hist_values, bin_edges, patches = plt.hist(sampled_lengths, bins=x[0:1001-13], alpha=0.7, label='Sampled Values')\n","  plt.xlabel('X-axis label')\n","  plt.ylabel('Frequency')\n","  plt.legend()\n","  plt.show()\n","\n","  uniprot_length_dist = list(zip([int(edge) for edge in bin_edges],[int(value) for value in hist_values]))\n","  with open(len_dist_filepath, \"w\") as f:\n","      json.dump(uniprot_length_dist, f)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uwjMF8nmSaNt"},"outputs":[],"source":["from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer\n","model = AutoModelForCausalLM.from_pretrained(\"lightonai/RITA_xl\", trust_remote_code=True)\n","tokenizer = AutoTokenizer.from_pretrained(\"lightonai/RITA_xl\")\n","model.to('cuda')\n","\n","from transformers import pipeline\n","rita_gen = pipeline('text-generation', model=model, tokenizer= tokenizer, trust_remote_code=True, device=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kScOktKo548g"},"outputs":[],"source":["i = 0\n","meta_data = {}\n","while i < 10000:\n","  if all_metadata_df.empty:\n","    max_length = max([l[0] for l in uniprot_length_dist])\n","  else:\n","    sampling_lengths = {s: n for s, n in uniprot_length_dist if n > 0}\n","    for l in all_metadata_df[\"conditions\"].str.extract(r'length = (\\d+)', expand=False).astype(int):\n","      if l >= 14 and l in sampling_lengths.keys():\n","        sampling_lengths[l] = sampling_lengths[l] -1\n","    sampling_lengths = {s: n for s, n in sampling_lengths.items() if n > 0}\n","    max_length = max(sampling_lengths.keys())\n","    print(\"Max generation length: \" + str(max_length))\n","\n","  meta_data['entity_id'] = str(uuid.uuid4())\n","  meta_data[\"batch_id\"] = None\n","  meta_data[\"batch_size\"] = None\n","  meta_data['output_file_name'] = None\n","  meta_data[\"timestamp\"] = str(datetime.now())\n","  meta_data['model'] = 'Rita'\n","  meta_data['task'] = 'sequence_generation'\n","  meta_data['wall_time_batch'] = None\n","  meta_data['conditions'] = 'max length = ' + str(max_length)\n","  meta_data['gpu'] = 'T4 GPU'\n","\n","  start_time = time.time()\n","  sequences = rita_gen(\"M\", max_length=max_length, do_sample=True, top_k=950, repetition_penalty=1.2,\n","                     num_return_sequences=1, eos_token_id=2)\n","  end_time = time.time()\n","  meta_data['wall_time_task'] = str(end_time-start_time) + \" Seconds\"\n","  sequence = sequences[0]['generated_text'].replace(' ', '')\n","  print(sequence)\n","  length = len(sequence)\n","  print(\"Generated length: \" + str(length))\n","  meta_data['conditions'] = 'length = ' + str(length)\n","  meta_data['generated_sequence'] = sequence\n","  metadata_entry = pd.Series(meta_data)\n","  all_metadata_df = pd.concat([all_metadata_df,pd.DataFrame(metadata_entry).T], ignore_index=True)\n","  i = i + 1\n","  if i % 5 == 0:\n","    all_metadata_df.to_csv(meta_data_filepath, index=False)\n","    print(\"saved to metadata \" + str(datetime.now()))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}